# ğŸ—‚ï¸ PresentaciÃ³nâ€¯â€”â€¯Modelos de Lenguaje (LLM) y Arquitecturas de Agentes

<!--
Si utilizas Reveal.js, separa cada diapositiva con "---".
-->

## 1.â€¯Agenda

1. IntroducciÃ³n a los LLM
2. Panorama de modelos comerciales y openâ€‘source
3. Arquitecturas de agentes
4. **Ciclo de vida de desarrollo de software con LLMs**
5. Herramientas y frameworks
6. Model Context Protocol (MCP)
7. MÃ©tricas y evaluaciÃ³n
8. Desarrollo y despliegue
9. Casos de uso
10. Seguridad y Ã©tica
11. OptimizaciÃ³n y escalabilidad
12. Tendencias futuras
13. Referencias

---

## 2.â€¯IntroducciÃ³n a los LLM

* **Â¿QuÃ© es un LLM?** Modelo de redes neuronales preentrenado a gran escala capaz de comprender y generar lenguaje natural.
* **Capacidades clave**: comprensiÃ³n contextual, razonamiento, generaciÃ³n de texto, traducciÃ³n, sumarizaciÃ³n.
* **Limitaciones**: alucinaciones, sesgos, sensibilidad al prompt, coste computacional.

---

## 3.â€¯Panorama de Modelos

### 3.1â€¯Modelos de OpenAI

| Modelo            | Ventajas                                        | Desventajas                        |
| ----------------- | ----------------------------------------------- | ---------------------------------- |
| **GPTâ€‘3.5â€‘turbo** | Bajo coste, baja latencia.                      | Menor capacidad de razonamiento.   |
| **GPTâ€‘4**         | Alta precisiÃ³n y alineaciÃ³n.                    | Coste y latencia mayores.          |
| **GPTâ€‘4â€‘turbo**   | Rendimiento optimizado (mejor precio/latencia). | AÃºn en beta para algunas regiones. |

### 3.2â€¯Modelos de Otros Proveedores

| Proveedor           | Modelo principalÂ (2025)           | Destacado                                                          |
| ------------------- | --------------------------------- | ------------------------------------------------------------------ |
| **Anthropic**       | **ClaudeÂ 3**                      | Enfoque en alineaciÃ³n y seguridad; ventana de contextoÂ 200â€¯k.      |
| **GoogleÂ DeepMind** | **GeminiÂ 1.5â€¯Pro / PaLMâ€¯2**       | Capacidades multimodales y multilingÃ¼es; servicio en GoogleÂ Cloud. |
| **Meta**            | **LLaMAÂ 3**                       | Openâ€‘source, mejores benchmarks por parÃ¡metro, variantesÂ 8â€‘400â€¯B.  |
| **Mistralâ€¯AI**      | **Mixtralâ€‘8x22B / Mistralâ€‘Large** | Arquitecturaâ€¯MoE eficiente; alto throughput de tokens.             |
| **xAI**             | **Grokâ€‘1.5**                      | VentanaÂ 128â€¯k; pesos abiertos anunciados.                          |
| **Perplexityâ€¯AI**   | **PPLXâ€‘Llamaâ€‘3â€‘70Bâ€‘Chat**         | Fineâ€‘tune para bÃºsqueda conversacional.                            |
| **Cohere**          | **Commandâ€‘R+ / Embedâ€‘v3**         | Optimizado para RAG (grounding) y embeddings de alta cobertura.    |
| *OtrosÂ openâ€‘source* | **Zephyrâ€‘7B, Phiâ€‘3â€‘mini**         | Modelos compactos con licencias permisivas.                        |

\-----------|--------|-------|
\| **Anthropic** | **ClaudeÂ 3** | Foco en seguridad y respuestas largas. |
\| **Google DeepMind** | **GeminiÂ 1.5 / PaLMÂ 2** | Multimodal y multilingÃ¼e. |
\| **Meta** | **LLaMAÂ 2 / 3** | Openâ€‘source, variantesÂ 7â€‘70â€¯B. |
\| **Mistralâ€¯AI** | **Mistralâ€‘Large / Mixtralâ€‘8x22B** | MoE con 22â€¯B rutas, SOTA en eficiencia. |
\| **xAI** | **Grokâ€‘1.5** | Contexto ampliado, openâ€‘weights anunciados. |
\| **Perplexityâ€¯AI** | **PPLXâ€‘Llamaâ€‘3â€‘70Bâ€‘Instruct** | Fineâ€‘tune para bÃºsqueda conversacional. |
\| **Cohere** | **Commandâ€‘R+** | Optimizado para RAG y grounding. |
\| *Openâ€‘source* | **Mistralâ€‘7B, Zephyrâ€‘7B, Phiâ€‘3â€‘mini** | Modelos compactos y permissiveâ€‘license.

\-----------|--------|-------|
\| **Anthropic** | **ClaudeÂ 3** | Foco en seguridad y respuestas largas. |
\| **Google DeepMind** | **GeminiÂ 1.5 / PaLMÂ 2** | Multimodal y multilingÃ¼e. |
\| **Meta** | **LLaMAÂ 2 / 3** | Openâ€‘source, variantes 7â€‘70â€¯B. |
\| *Openâ€‘source* | **Mistralâ€‘7B, Mixtralâ€‘8x7B** | Arquitectura Mixtureâ€‘ofâ€‘Experts.

---

## 4.â€¯Arquitecturas de Agentes

### 4.1â€¯Agente Simple

```mermaid
graph LR
    A[Input] --> B[LLM]
    B --> C[Output]
```

**Uso**: tareas adâ€‘hoc sin memoria (ej. Q\&A breve).

### 4.2â€¯Agente con Memoria

```mermaid
graph LR
    A[Input] --> B[LLM]
    B --> C[Output]
    C --> D[Memory]
    D --> B
```

**Uso**: chat continuo, asistentes personales.

### 4.3â€¯Agente con Herramientas (ReActÂ ğŸ“–Â \[7])

```mermaid
graph TD
    A[Input] --> B[LLM]
    B --> C{DecisiÃ³n}
    C -->|API| D["ğŸ”Â Search"]
    C -->|CÃ³digo| E["ğŸ§®Â Executor"]
    C -->|DB| F["ğŸ“šÂ DB"]
    D & E & F --> G[Output]
```

### 4.4â€¯Multiâ€‘Agente / Router

```mermaid
graph TD
    A[Input] --> B[Router]
    B --> C[AgenteÂ Legal]
    B --> D[AgenteÂ TÃ©cnico]
    B --> E[AgenteÂ AnalÃ­tico]
    C & D & E --> F[Output]
```

### 4.5â€¯Agenteâ€¯Reflexivo (ReflexionÂ ğŸ“–Â \[8])

```mermaid
graph TD
    A[Input] --> B[LLM]
    B --> C[ReflexiÃ³n]
    C -->|Mejora| B
    B --> D[Output]
```

### 4.6â€¯Agenteâ€¯MoE / Enrutadorâ€‘deâ€‘Expertos

```mermaid
graph TD
    A[Input] --> B[Enrutador]
    B --> C[Expertoâ€¯1]
    B --> D[Expertoâ€¯2]
    B --> E[Expertoâ€¯n]
    C & D & E --> F[Output]
```

**Uso**: Modelos Mixtureâ€‘ofâ€‘Experts (p.â€¯ej., Mixtralâ€‘8x22B) que activan subâ€‘modelos especializados para escalar sin aumentar latencia.

### 4.7â€¯Agenteâ€¯Hierarchical Task Decomposition (HTD)

```mermaid
graph TD
    A[Goal] --> B[PlannerÂ LLM]
    B --> C[Subâ€‘taskâ€¯1Â Agent]
    B --> D[Subâ€‘taskâ€¯2Â Agent]
    C & D --> E[Aggregator]
    E --> F[Output]
```

**Uso**: Descomponer objetivos complejos en subtareas, asignadas a agentes especializados, inspirado en "Generative Agents" y "LATS".

---

## 5.â€¯Ciclo de Vida de Desarrollo de Software con LLMs

### 5.1â€¯Fases Principales

| Fase                                    | Objetivo                                                                                  | Entregables                                  | Herramientas Sugeridas                                                                              |
| --------------------------------------- | ----------------------------------------------------------------------------------------- | -------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| **1. IdeaciÃ³n & Requisitos**            | Identificar problemas y casos de uso donde un LLM aporte valor.                           | Historias de usuario, mÃ©tricas de Ã©xito.     | Miro, Jira, Confluence, Notion, ChatGPT/Claude para brainstorming                                   |
| **2. DiseÃ±o de Prompts & Arquitectura** | Especificar prompts, elegir approach (RAG, KGâ€‘RAG, Tools) y definir diagramas de agentes. | Documentos de diseÃ±o, prototipos de prompt.  | PromptLayer, Humanloop, LangSmith Playground, Mermaid / diagrams.net, LlamaIndex, LangChain Schemas |
| **3. SelecciÃ³n / Fineâ€‘Tuning**          | Escoger modelo base o entrenar/fineâ€‘tune con datos privativos.                            | Checkpoints del modelo, evaluaciÃ³n offline.  | Hugging Face Transformers, PEFT/LoRA, NVIDIA NeMo, Weights & Biases, vLLM, Azureâ€¯OpenAI FT UI       |
| **4. IntegraciÃ³n & OrquestaciÃ³n**       | Conectar LLM con APIs, bases de datos y UIs; implementar guards y control de costos.      | CÃ³digo de servicios, pruebas de integraciÃ³n. | LangChain, LlamaIndex, OpenAI AssistantsÂ API, FastAPI, Airflow/Prefect, AWSÂ StepÂ Functions          |
| **5. Pruebas & EvaluaciÃ³n**             | Validar precisiÃ³n, seguridad y UX usando mÃ©tricas automÃ¡ticas + revisiÃ³n humana.          | Reportes de pruebas, aceptaciÃ³n de producto. | LangSmith Eval, TruLens, Promptfoo, OpenAIÂ Evals, LlamaIndex Eval, pytest, Playwright               |
| **6. Despliegue (CI/CD)**               | Automatizar releases, canary, rollback; infraestructura reproducible.                     | Pipelines CI/CD, manifiestos Terraform.      | GitHubâ€¯Actions, GitLabâ€¯CI/CD, Docker, Terraform, Helm, ArgoCD, Spinnaker                            |
| **7. Observabilidad & Monitoreo**       | Rastrear trazas, latencia, costos y seguridad (LLMOps).                                   | Dashboards, alertas, datasets de logs.       | OpenTelemetry, ArizeÂ Phoenix, PromptLayer, Grafana, Prometheus, Datadog, Sentry                     |
| **8. Mejora Continua**                  | Recopilar feedback de producciÃ³n, reâ€‘entrenar y refinar prompts/modelos.                  | Backlog de mejoras, modelos actualizados.    | LabelÂ Studio, Segment, Amplitude, MLflow/Kubeflow, activeâ€‘learning pipelines                        |

### 5.2â€¯Diagrama de Flujo (Mermaid)â€¯Diagrama de Flujo (Mermaid)

```mermaid
graph LR
    A[IdeaciÃ³n] --> B[DiseÃ±o de Prompts]
    B --> C[Fineâ€‘Tuning / SelecciÃ³n]
    C --> D[IntegraciÃ³n & OrquestaciÃ³n]
    D --> E[Pruebas & EvaluaciÃ³n]
    E --> F[Despliegue]
    F --> G[Observabilidad]
    G --> H[Mejora Continua]
    H --> B
```

### 5.3â€¯Roles Clave

* **Product Owner / UX**: define valor de negocio y criterios de Ã©xito.
* **Software Developers**: implementan funcionalidades, integran APIs de LLM/RAG y mantienen el cÃ³digo.
* **Prompt Engineer**: diseÃ±a y prueba prompts / system messages.
* **ML Engineer**: fineâ€‘tune, evalÃºa y optimiza modelos.
* **DevOps / LLMOps**: CI/CD, escalabilidad, monitoreo.
* **Security & Compliance**: revisa PII, polÃ­ticas y auditorÃ­as.

### 5.4â€¯Buenas PrÃ¡cticasâ€¯Buenas PrÃ¡cticas

1. **Shiftâ€‘Left Testing**: validar prompts y seguridad desde fases tempranas.
2. **Data Contracts**: versionar datasets de entrenamiento y RAG.
3. **Humanâ€‘inâ€‘theâ€‘Loop**: bucles de revisiÃ³n humana para casos crÃ­ticos.
4. **Blue/Green o Canary Deploys** para minimizar riesgo.
5. **Continuous Evaluation** con benchmarks y evaluadores automÃ¡ticos (p.â€¯ej., LlamaIndex Eval o GPTâ€‘Judge).

### 5.5 Diagrama de Interacciones (Mermaid)

```mermaid
sequenceDiagram
    autonumber
    participant PO as Product Owner
    participant PE as Prompt Engineer
    participant DEV as Software Developer
    participant MLE as ML Engineer
    participant DevOps as DevOps / LLMOps
    participant SEC as Security
    participant USER as End User

    PO->>PE: Historias de usuario y criterios
    PE->>DEV: Especificaciones de prompt / API
    DEV->>MLE: Datos de entrenamiento & contratos
    MLE->>DEV: Modelo fineâ€‘tuned & endpoints
    DEV->>DevOps: Artefactos listos para despliegue
    DevOps->>SEC: AuditorÃ­a & guardrails
    SEC-->>DevOps: OK / Observaciones
    DevOps->>USER: Despliegue canary
    USER-->>PO: Feedback & mÃ©tricas
    PO->>PE: Nuevos requisitos
```

\--------|---------|-------------|
\| **Secuencial** | Pasos estrictamente en cadena. | ETL, pipelines deterministas. |
\| **Paralelo** | MÃºltiples ramas simultÃ¡neas. | AnÃ¡lisis en lote o fusiÃ³n de fuentes. |
\| **Condicional** | Ramas basadas en lÃ³gica. | Flujos con reglas o clasificadores. |
\| **Iterativo** | Bucle de mejora (reflexiÃ³n/pruebas). | OptimizaciÃ³n de respuestas. |

---

## 6.â€¯Herramientas y Frameworks

### Frameworks para Agentes

* **LangChainâ€¯\[9]** â€¢ **LangGraph** â€¢ **LlamaIndex** â€¢ **AutoGPTâ€¯\[11]** â€¢ **BabyAGIâ€¯\[12]**
* **OpenAI Assistants API**: orquestaciÃ³n nativa de herramientas

### Almacenamiento y RecuperaciÃ³n

* **Vector Stores**: FAISS, Pinecone, Weaviate
* **Graph Stores**: Neo4j, TigerGraph, AmazonÂ Neptune

### Embeddings

* `textâ€‘embeddingâ€‘3â€‘large`, `allâ€‘MiniLMâ€‘L6`

### Retrievalâ€‘Augmented Generation (RAG)

* **Standard RAG**: bÃºsqueda vectorial + generaciÃ³n
* **KGâ€‘RAG (RAGâ€¯+â€¯Knowledgeâ€¯Graph)**: fusiona contexto vectorial con grafos de conocimiento para respuestas mÃ¡s precisas y trazables
  **Frameworks**: ArizeÂ Phoenixâ€¯KGâ€‘RAG, Neo4jâ€¯GenAI, GraphRAGÂ (LlamaIndex)

### OrquestaciÃ³n y Observabilidad

* **Airflow / Prefect**: pipelines programables
* **OpenTelemetry**: trazas unificadas para LLMs
* **ArizeÂ Phoenix**: monitoreo y depuraciÃ³n de RAG/LLM

---

## 7.â€¯Model Context Protocol (MCP)

### 7.1â€¯VisiÃ³n General

El **Model Context Protocol (MCP)** es un estÃ¡ndar abierto que define **cÃ³mo** las aplicaciones proporcionan contexto y herramientas a los LLMs â€”similar a un "USBâ€‘C" para conectar fuentes de datos, APIs y capacidades externas de forma uniforme.â€¯îˆ€citeîˆ‚turn0search2îˆ

### 7.2â€¯Componentes Principales

* **MCP Host**: AplicaciÃ³n que aloja al agente (p.â€¯ej., un chat o dashboard).
* **MCP Client**: Manejador dentro del host que solicita acciones/contexto.
* **MCP Server(s)**: Puente hacia datos o herramientas concretas (CRM, GitHub, bases de conocimiento).â€¯îˆ€citeîˆ‚turn0search0îˆ‚turn0search1îˆ

### 7.3â€¯Arquitectura de Referencia

```mermaid
graph TD
    subgraph Host
        A[UI / Agent App]
        B[MCP Client]
    end
    subgraph External
        C[MCP Server 1]
        D[MCP Server 2]
    end
    subgraph Model
        E[LLM]
    end
    A --> B
    B --"MCP"--> C
    B --"MCP"--> D
    B -->|Prompt + Tools| E
    C -. datos .-> E
    D -. acciones .-> E
```

### 7.4â€¯Beneficios Clave

1. **Interoperabilidad**: Un solo protocolo para mÃºltiples fuentes y herramientas.
2. **Seguridad**: Control granular de permisos (readâ€‘only, readâ€‘write).â€¯îˆ€citeîˆ‚turn0search6îˆ
3. **Escalabilidad**: Conectar nuevos backâ€‘ends sin reescribir prompts.
4. **Observabilidad**: Facilita trazas y auditorÃ­a de llamadas de herramienta.

### 7.5â€¯Ecosistema y Herramientas

| CategorÃ­a                  | Ejemplos                                                                                |
| -------------------------- | --------------------------------------------------------------------------------------- |
| **SDKs**                   | `openai-agents-python`â€¯îˆ€citeîˆ‚turn0search8îˆ, `lastmile-ai/mcp-agent`â€¯îˆ€citeîˆ‚turn0search3îˆ |
| **Servers Readyâ€‘Made**     | Replitâ€¯Codebaseâ€¯MCP, Anthropic Repo Connectorâ€¯îˆ€citeîˆ‚turn0news16îˆ                        |
| **Frameworks Compatibles** | LangChain, LangGraph, CrewAI, LlamaIndex                                                |

### 7.6â€¯Casos de Uso

* **Enterprise Agents**: Acceso seguro a Salesforce, SAP, GitHub.
* **RAG DinÃ¡mico**: Inyectar contexto de bases de conocimiento corporativas.
* **OrquestaciÃ³n de Herramientas**: LLM decide usar "crearâ€¯PR" o "consultarâ€¯DB" vÃ­a MCP.

## 8.â€¯MÃ©tricas y EvaluaciÃ³n y EvaluaciÃ³n

| MÃ©trica           | Â¿QuÃ© mide?                         |
| ----------------- | ---------------------------------- |
| **PrecisiÃ³n**     | CorrecciÃ³n factual.                |
| **Latencia**      | Tiempo medio de respuesta.         |
| **Costo**         | Tokens Ã— precio.                   |
| **Consistencia**  | Coherencia entre respuestas.       |
| **Tasa de Ã‰xito** | Respuestas satisfactorias / total. |

### Herramientas

* **LangSmith**: trazabilidad, costo y A/B.
* **LangWatch**: monitoreo en tiempo real y alertas.

---

## 9.â€¯Desarrollo y Despliegue y Despliegue

### 8.1â€¯MetodologÃ­as

* **Iterativo / Promptâ€‘Engineering**
* **TDD para agentes y flujos**
* **CI/CD + Canaryâ€¯Releases**

### 8.2â€¯Stack de Despliegue

| Capa               | OpciÃ³n                          |
| ------------------ | ------------------------------- |
| **Frontend**       | Next.js / Vercel                |
| **Backend**        | FastAPI / AWSÂ Lambda            |
| **Infra**          | Docker â€¢ Kubernetes â€¢ Terraform |
| **Observabilidad** | Prometheus â€¢ Grafana â€¢ Datadog  |

---

## 10.â€¯Casos de Uso

1. **Soporte al cliente**Â â†’ FAQ, routing, anÃ¡lisis de sentimiento.
2. **Desarrollo de software**Â â†’ asistentes de cÃ³digo, documentaciÃ³n.
3. **AnÃ¡lisis de datos**Â â†’ reportes automÃ¡ticos y dashboarding.
4. **AutomatizaciÃ³n de procesos**Â â†’ RPA + LLM para documentos.

---

## 11.â€¯Seguridad y Ã‰tica y Ã‰tica

* **ProtecciÃ³n de datos**: cifrado, PII redaction.
* **PrevenciÃ³n de abusos**: rateâ€‘limiting, filtros de contenido.
* **Transparencia & Sesgos**: system cards, auditorÃ­as, datasets diversos.

---

## 12.â€¯OptimizaciÃ³n y Escalabilidad y Escalabilidad

* **Costos**: caching, modelos mÃ¡s pequeÃ±os, batch.
* **Escalabilidad**: serverless, autoâ€‘scaling, horizontality.

---

## 13.â€¯Tendencias Futuras Futuras

* Agentes mÃ¡s autÃ³nomos (longâ€‘term planning).
* Mayor integraciÃ³n con APIs y herramientas externas.
* PersonalizaciÃ³n a nivel de usuario/vertical.
* Avances en alignment, seguridad y explicabilidad.

---

## 14.â€¯Referencias

1. T.â€¯Brownâ€¯etâ€¯al., â€œLanguage Models are Fewâ€‘Shot Learners,â€ *NeurIPS*,â€¯2020.
2. OpenAI, â€œGPTâ€‘4 Technical Report,â€â€¯2023.
3. S.â€¯Bubeckâ€¯etâ€¯al., â€œSparks of AGI: Early experiments with GPTâ€‘4,â€â€¯MSRÂ TRâ€‘2023â€‘8.
4. Anthropic, â€œClaudeÂ 3 System Card,â€â€¯2024.
5. A.â€¯Chowdheryâ€¯etâ€¯al., â€œPaLM: Scaling Language Modeling with Pathways,â€â€¯*arXiv*,â€¯2022.
6. H.â€¯Touvronâ€¯etâ€¯al., â€œLLaMAâ€¯2: Open Foundation and Fineâ€‘Tuned Chat Models,â€â€¯*arXiv*,â€¯2023.
7. S.â€¯Yaoâ€¯etâ€¯al., â€œReAct: Synergizing Reasoning and Acting in Language Models,â€â€¯*ICLR*,â€¯2023.
8. J.â€¯Shinnâ€¯&â€¯L.â€¯Labash, â€œReflexion: Language Agents with Internal Chain of Thought,â€â€¯*arXiv*,â€¯2023.
9. LangChainâ€¯Docs [https://python.langchain.com](https://python.langchain.com).
10. LangSmithâ€¯Docs [https://smith.langchain.com](https://smith.langchain.com).
11. *AutoGPT*Â GitHub Repository, SignificantÂ Gravitas,â€¯2023.
12. *BabyAGI*Â GitHub Repository, YoheiÂ Nakajima,â€¯2023.
13. P.â€¯Lewisâ€¯etâ€¯al., â€œRetrievalâ€‘Augmented Generation for Knowledgeâ€‘Intensive NLP Tasks,â€â€¯*arXiv*,â€¯2020.
14. Arizeâ€¯AI, â€œPhoenix: Openâ€‘Source Observability for LLMs and RAG,â€â€¯2024.
15. Neo4j, â€œGenAI Stack & Knowledgeâ€‘Graphâ€‘RAG,â€â€¯2024.
16. Mistralâ€¯AI, â€œMixtralâ€‘8x22B & Mistralâ€‘Large Technical Report,â€â€¯2024.
17. xAI, â€œGrokâ€‘1.5 Model Card,â€â€¯2024.
18. Cohere, â€œCommandâ€‘R+ Technical Overview,â€â€¯2024.
19. Perplexityâ€¯AI, â€œPPLX Llamaâ€‘3 70B Release Notes,â€â€¯2025.
20. S.â€¯Fedusâ€¯etâ€¯al., â€œSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,â€â€¯*arXiv*,â€¯2021.
21. X.â€¯Liâ€¯etâ€¯al., â€œHierarchical Planning for Languageâ€‘Based Agents,â€â€¯*arXiv*,â€¯2024.
22. Modelâ€¯Contextâ€¯Protocol Docs [https://modelcontextprotocol.io](https://modelcontextprotocol.io).
23. T.â€¯Balarabe, â€œWhat is Model Context Protocol? Architecture Overview,â€ *Medium*,â€¯2025.

---
